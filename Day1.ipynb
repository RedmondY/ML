{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 机器学习的一些概念  \n",
    "  \n",
    "1.1 有监督\n",
    "监督，通俗来讲就是分类，就是把训练样本，在某种评价下得到最佳的模型，然后再利用这个模型将输入映射为相应的输出，对输出进行简单的判断从而实现分类的目的。  \n",
    "\n",
    "1.2 无监督\n",
    "无监督，我们事先没有任何训练样本，而直接对数据进行建模。比如我们去参观一个画展，我们完全对艺术一无所知,但是欣赏完多幅作品之后，我们也能把它们分成不同的派别。  \n",
    "\n",
    "1.3 泛化能力\n",
    "学习方法的泛化能力（generalization ability）是指由该学习方法学习到的模型对位置数据的预测能力，是学习方法本质上重要的性质。    \n",
    "\n",
    "1.4 过拟合与欠拟合\n",
    "过拟合(over-fitting)：如果一味追求提高对训练数据的预测能力，所选模型的复杂程度则往往会比真模型高。这种现象称为过拟合（over-fitting）。简言之，也就是学习器把训练样本学得“太好”了得时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一些性质，这样就会导致泛化能力差。   \n",
    "解决过拟合的方法：正则化（regularization），正则化是结构风险最小化策略的实现，是在经验风险上加一个正则项（regualrizer）或惩罚项（penalty term）。  \n",
    "欠拟合（underfitting):是指是对训练样本的一般性质尚未学好。  \n",
    "解决欠拟合的方法：可以增大数据集，增加训练轮数。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 线性回归的原理  \n",
    "\n",
    "线性回归使用最佳的拟合直线在因变量和一个或多个自变量之间建立一种关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 线性回归损失函数、代价函数、目标函数  \n",
    "\n",
    "3.1损失函数（loss）  \n",
    "样本模型真实值（y）和预测值(y_)的误差，即loss=(y-y_)^2,损失函数越小，说明拟合的越好，模型亦越好。  \n",
    "3.2代价函数（cost）  \n",
    "定义在整个训练集上的，整个样本误差的平均，即损失函数的平均值。  \n",
    "cost = 1/m*sigma(y-y_)^2    \n",
    "3.3 目标函数   \n",
    "[链接](https://blog.csdn.net/qq_33414271/article/details/78693758)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 优化方法(梯度下降法、牛顿法、拟牛顿法等)  \n",
    "\n",
    "#### 梯度下降法\n",
    "\n",
    "沿着梯度下降的方向来求出损失函数的极小值。梯度下降不一定能够找到全局的最优解，有可能是一个局部最优解。当然，如果损失函数是凸函数，梯度下降法得到的解就一定是全局最优解。  \n",
    "\n",
    "#### 牛顿法  \n",
    "\n",
    "牛顿法是一种在实数域和复数域上近似求解方程的方法。方法使用函数f (x)的泰勒级数的前面几项来寻找方程f (x)求导 = 0的根。牛顿法最大的特点就在于它的收敛速度很快。  \n",
    "\n",
    "#### 拟牛顿法  \n",
    "\n",
    "拟牛顿法的本质思想是改善牛顿法每次需要求解复杂的Hessian矩阵的逆矩阵的缺陷，它使用正定矩阵来近似Hessian矩阵的逆，从而简化了运算的复杂度。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 线性回归的评估指标  \n",
    "\n",
    "[链接](https://www.cnblogs.com/zzzzy/p/8490662.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. sklearn参数详解  \n",
    "\n",
    "fit_intercept : 布尔型，默认为true  \n",
    "是否对训练数据进行中心化。如果该变量为false，则表明输入的数据已经进行了中心化，在下面的过程里不进行中心化处理；否则，对输入的训练数据进行中心化处理  \n",
    "normalize :布尔型，默认为false  \n",
    "是否对回归量进行归一化。  \n",
    "copy_X: 布尔型，默认为true  \n",
    "是否对X复制，如果选择false，则直接对原数据进行覆盖。  \n",
    "n_jobs : 整型， 默认为1线程数。  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
